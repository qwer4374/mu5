#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AI Service
==========

Advanced AI service providing intelligent features like content analysis,
smart recommendations, automated responses, and predictive analytics.
"""

import logging
import asyncio
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse
import openai

class AIService:
    """Advanced AI service with multiple intelligent features."""
    
    def __init__(self, config):
        """Initialize AI service."""
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Initialize OpenAI client
        self.openai_client = openai.AsyncOpenAI()
        
        # AI model configurations
        self.models = {
            'content_analysis': 'gpt-3.5-turbo',
            'recommendations': 'gpt-3.5-turbo',
            'chat_response': 'gpt-3.5-turbo',
            'text_generation': 'gpt-3.5-turbo',
            'translation': 'gpt-3.5-turbo'
        }
        
        # Cache for AI responses
        self.response_cache = {}
        self.cache_ttl = 3600  # 1 hour
    
    async def analyze_content(self, content: str, content_type: str = 'text') -> Dict[str, Any]:
        """Analyze content using AI for safety, quality, and categorization."""
        try:
            cache_key = f"content_analysis_{hash(content)}"
            
            # Check cache first
            if cache_key in self.response_cache:
                cached_result = self.response_cache[cache_key]
                if datetime.now().timestamp() - cached_result['timestamp'] < self.cache_ttl:
                    return cached_result['data']
            
            # Prepare analysis prompt
            prompt = f"""
            ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„:

            Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content_type}
            Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content[:1000]}...

            ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ù†ÙˆØ§Ø­ÙŠ Ø§Ù„ØªØ§Ù„ÙŠØ©:
            1. Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© (Ù‡Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¢Ù…Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨ØŸ)
            2. Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©
            3. Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„ÙØ¦Ø©
            4. Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
            5. Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ù†Ø¨Ø±Ø©
            6. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            7. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†

            Ù‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON Ù…Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªØ§Ù„ÙŠØ©:
            - safety_score (0-100)
            - quality_score (0-100)
            - category
            - language
            - sentiment
            - keywords
            - recommendations
            - is_appropriate (true/false)
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['content_analysis'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            # Parse AI response
            ai_response = response.choices[0].message.content
            
            try:
                # Try to parse as JSON
                analysis_result = json.loads(ai_response)
            except json.JSONDecodeError:
                # Fallback to basic analysis
                analysis_result = self._basic_content_analysis(content)
            
            # Add additional analysis
            analysis_result.update({
                'content_length': len(content),
                'word_count': len(content.split()),
                'analysis_timestamp': datetime.now().isoformat(),
                'readability_score': self._calculate_readability(content),
                'spam_indicators': self._detect_spam_indicators(content)
            })
            
            # Cache result
            self.response_cache[cache_key] = {
                'data': analysis_result,
                'timestamp': datetime.now().timestamp()
            }
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"Error in content analysis: {e}")
            return self._basic_content_analysis(content)
    
    async def generate_smart_response(self, user_message: str, user_context: Dict[str, Any]) -> str:
        """Generate intelligent response based on user message and context."""
        try:
            # Prepare context information
            context_info = f"""
            Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
            - Ø§Ù„Ø§Ø³Ù…: {user_context.get('first_name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
            - Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙØ¶Ù„Ø©: {user_context.get('language_code', 'ar')}
            - Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª: {user_context.get('download_count', 0)}
            - Ø¢Ø®Ø± Ù†Ø´Ø§Ø·: {user_context.get('last_activity', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
            - Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_context.get('user_level', 'Ù…Ø¨ØªØ¯Ø¦')}
            """
            
            prompt = f"""
            Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ø¨ÙˆØª ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø±Ø³Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:
            "{user_message}"

            {context_info}

            Ù‚Ø¯Ù… Ø±Ø¯Ø§Ù‹ Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯:
            - ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ù‡Ø°Ø¨
            - Ù…ÙÙŠØ¯ ÙˆØ¹Ù…Ù„ÙŠ
            - Ù…Ù†Ø§Ø³Ø¨ Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            - ÙŠØªØ¶Ù…Ù† Ø¥Ø±Ø´Ø§Ø¯Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            - Ù„Ø§ ÙŠØ²ÙŠØ¯ Ø¹Ù† 200 ÙƒÙ„Ù…Ø©
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['chat_response'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø¨ÙˆØª ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§ØªØŒ ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ù‡Ù†ÙŠØ©."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"Error generating smart response: {e}")
            return "Ø´ÙƒØ±Ø§Ù‹ Ù„Ø±Ø³Ø§Ù„ØªÙƒ! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
    
    async def generate_personalized_recommendations(self, user_id: int, user_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate personalized recommendations for the user."""
        try:
            # Analyze user behavior patterns
            download_history = user_data.get('download_history', [])
            preferences = user_data.get('preferences', {})
            activity_patterns = user_data.get('activity_patterns', {})
            
            # Prepare recommendation prompt
            prompt = f"""
            Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ© Ù…ÙÙŠØ¯Ø©:

            Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©:
            {json.dumps(download_history[-10:], ensure_ascii=False, indent=2)}

            Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª:
            {json.dumps(preferences, ensure_ascii=False, indent=2)}

            Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø´Ø§Ø·:
            {json.dumps(activity_patterns, ensure_ascii=False, indent=2)}

            Ù‚Ø¯Ù… 5 ØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ© ÙÙŠ ØµÙŠØºØ© JSON Ù…Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ÙƒÙ„ ØªÙˆØµÙŠØ©:
            - title: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªÙˆØµÙŠØ©
            - description: ÙˆØµÙ Ù…ÙØµÙ„
            - action: Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            - priority: Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© (high/medium/low)
            - category: Ø§Ù„ÙØ¦Ø© (download/settings/feature/tip)
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['recommendations'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ© Ù…ÙÙŠØ¯Ø©."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=800
            )
            
            try:
                recommendations = json.loads(response.choices[0].message.content)
                if isinstance(recommendations, list):
                    return recommendations
                elif isinstance(recommendations, dict) and 'recommendations' in recommendations:
                    return recommendations['recommendations']
            except json.JSONDecodeError:
                pass
            
            # Fallback recommendations
            return self._generate_fallback_recommendations(user_data)
            
        except Exception as e:
            self.logger.error(f"Error generating recommendations: {e}")
            return self._generate_fallback_recommendations(user_data)
    
    async def analyze_url_safety(self, url: str) -> Dict[str, Any]:
        """Analyze URL for safety and legitimacy."""
        try:
            # Parse URL
            parsed_url = urlparse(url)
            domain = parsed_url.netloc.lower()
            
            # Basic safety checks
            safety_analysis = {
                'url': url,
                'domain': domain,
                'is_https': parsed_url.scheme == 'https',
                'safety_score': 50,  # Default neutral score
                'risk_level': 'medium',
                'warnings': [],
                'recommendations': []
            }
            
            # Check against known safe/unsafe patterns
            safe_domains = ['youtube.com', 'youtu.be', 'drive.google.com', 'dropbox.com', 'mega.nz']
            suspicious_patterns = ['bit.ly', 'tinyurl.com', 'short.link']
            
            if any(safe_domain in domain for safe_domain in safe_domains):
                safety_analysis['safety_score'] = 85
                safety_analysis['risk_level'] = 'low'
            elif any(pattern in domain for pattern in suspicious_patterns):
                safety_analysis['safety_score'] = 30
                safety_analysis['risk_level'] = 'high'
                safety_analysis['warnings'].append('Ø±Ø§Ø¨Ø· Ù…Ø®ØªØµØ± - Ù‚Ø¯ ÙŠØ®ÙÙŠ Ø§Ù„ÙˆØ¬Ù‡Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©')
            
            # Check for suspicious patterns in URL
            if re.search(r'[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}', domain):
                safety_analysis['warnings'].append('Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ³ØªØ®Ø¯Ù… Ø¹Ù†ÙˆØ§Ù† IP Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù†Ø·Ø§Ù‚')
                safety_analysis['safety_score'] -= 20
            
            if len(domain.split('.')) > 4:
                safety_analysis['warnings'].append('Ù†Ø·Ø§Ù‚ ÙØ±Ø¹ÙŠ Ù…Ø¹Ù‚Ø¯ - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø´Ø¨ÙˆÙ‡Ø§Ù‹')
                safety_analysis['safety_score'] -= 10
            
            # Use AI for additional analysis
            ai_analysis = await self._ai_url_analysis(url)
            safety_analysis.update(ai_analysis)
            
            return safety_analysis
            
        except Exception as e:
            self.logger.error(f"Error analyzing URL safety: {e}")
            return {
                'url': url,
                'safety_score': 50,
                'risk_level': 'unknown',
                'warnings': ['ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·'],
                'recommendations': ['ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„']
            }
    
    async def _ai_url_analysis(self, url: str) -> Dict[str, Any]:
        """Use AI to analyze URL for additional insights."""
        try:
            prompt = f"""
            Ø­Ù„Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©:
            {url}

            Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙŠØªØ¶Ù…Ù†:
            1. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù…Ø§Ù† (0-100)
            2. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø± (low/medium/high)
            3. Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
            4. Ø§Ù„ØªÙˆØµÙŠØ§Øª

            Ù‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON Ù…Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­:
            - ai_safety_score
            - ai_risk_assessment
            - ai_warnings (array)
            - ai_recommendations (array)
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['content_analysis'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø£Ù…Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ§Ù„Ù…ÙˆØ§Ù‚Ø¹."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=400
            )
            
            try:
                return json.loads(response.choices[0].message.content)
            except json.JSONDecodeError:
                return {}
                
        except Exception as e:
            self.logger.error(f"Error in AI URL analysis: {e}")
            return {}
    
    async def generate_download_summary(self, download_data: Dict[str, Any]) -> str:
        """Generate intelligent summary for download completion."""
        try:
            prompt = f"""
            Ø£Ù†Ø´Ø¦ Ù…Ù„Ø®ØµØ§Ù‹ Ø°ÙƒÙŠØ§Ù‹ Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ©:

            Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„:
            - Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: {download_data.get('filename', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
            - Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {download_data.get('file_size_mb', 0)} MB
            - Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù: {download_data.get('file_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
            - Ù…Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„: {download_data.get('duration_seconds', 0)} Ø«Ø§Ù†ÙŠØ©
            - Ø­Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„: {download_data.get('status', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
            - Ø§Ù„Ù…ØµØ¯Ø±: {download_data.get('source_domain', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}

            Ø£Ù†Ø´Ø¦ Ù…Ù„Ø®ØµØ§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ (50-100 ÙƒÙ„Ù…Ø©) ÙŠØªØ¶Ù…Ù†:
            - ØªØ£ÙƒÙŠØ¯ Ù†Ø¬Ø§Ø­/ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„
            - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ø¹Ù† Ø§Ù„Ù…Ù„Ù
            - Ù†ØµØ§Ø¦Ø­ Ø£Ùˆ ØªÙˆØµÙŠØ§Øª Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            - Ø±Ø³Ø§Ù„Ø© ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ø´Ø¬Ø¹Ø©
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['text_generation'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠÙ‚Ø¯Ù… Ù…Ù„Ø®ØµØ§Øª Ù…ÙÙŠØ¯Ø© ÙˆÙˆØ¯ÙˆØ¯Ø© Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"Error generating download summary: {e}")
            return f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {download_data.get('filename', '')} Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰"
    
    async def translate_text(self, text: str, target_language: str = 'ar') -> str:
        """Translate text to target language."""
        try:
            if not text.strip():
                return text
            
            # Check if translation is needed
            if target_language == 'ar' and self._is_arabic_text(text):
                return text
            elif target_language == 'en' and self._is_english_text(text):
                return text
            
            language_names = {
                'ar': 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©',
                'en': 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©',
                'fr': 'Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©',
                'es': 'Ø§Ù„Ø¥Ø³Ø¨Ø§Ù†ÙŠØ©',
                'de': 'Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©'
            }
            
            target_lang_name = language_names.get(target_language, target_language)
            
            prompt = f"""
            ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ {target_lang_name}:
            
            "{text}"
            
            Ù‚Ø¯Ù… Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙÙ‚Ø· Ø¯ÙˆÙ† Ø£ÙŠ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['translation'],
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…ØªØ±Ø¬Ù… Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¥Ù„Ù‰ {target_lang_name}."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=len(text) * 2
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"Error translating text: {e}")
            return text  # Return original text if translation fails
    
    async def generate_help_content(self, user_query: str, user_level: str = 'beginner') -> str:
        """Generate contextual help content based on user query."""
        try:
            level_descriptions = {
                'beginner': 'Ù…Ø¨ØªØ¯Ø¦ ÙŠØ­ØªØ§Ø¬ Ø´Ø±Ø­ Ù…ÙØµÙ„ ÙˆØ¨Ø³ÙŠØ·',
                'intermediate': 'Ù…ØªÙˆØ³Ø· ÙŠÙÙ‡Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª',
                'advanced': 'Ù…ØªÙ‚Ø¯Ù… ÙŠØ­ØªØ§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ©'
            }
            
            prompt = f"""
            Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ({level_descriptions.get(user_level, 'Ù…Ø¨ØªØ¯Ø¦')}) ÙŠØ³Ø£Ù„:
            "{user_query}"

            Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙÙŠØ¯Ø© ÙˆÙ…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…Ø³ØªÙˆØ§Ù‡ ØªØªØ¶Ù…Ù†:
            1. Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„
            2. Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            3. Ù†ØµØ§Ø¦Ø­ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙÙŠØ¯Ø©
            4. Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†

            Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙŠØ¯Ø© ÙˆÙ„Ø§ ØªØ²ÙŠØ¯ Ø¹Ù† 300 ÙƒÙ„Ù…Ø©.
            """
            
            response = await self.openai_client.chat.completions.create(
                model=self.models['chat_response'],
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙŠØ¯Ø©."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"Error generating help content: {e}")
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ."
    
    # Helper methods
    def _basic_content_analysis(self, content: str) -> Dict[str, Any]:
        """Provide basic content analysis without AI."""
        return {
            'safety_score': 70,
            'quality_score': 60,
            'category': 'general',
            'language': 'ar' if self._is_arabic_text(content) else 'en',
            'sentiment': 'neutral',
            'keywords': self._extract_basic_keywords(content),
            'recommendations': ['Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ¨Ø¯Ùˆ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø§Ù…'],
            'is_appropriate': True
        }
    
    def _is_arabic_text(self, text: str) -> bool:
        """Check if text is primarily Arabic."""
        arabic_chars = sum(1 for char in text if '\u0600' <= char <= '\u06FF')
        return arabic_chars > len(text) * 0.3
    
    def _is_english_text(self, text: str) -> bool:
        """Check if text is primarily English."""
        english_chars = sum(1 for char in text if char.isalpha() and ord(char) < 128)
        return english_chars > len(text) * 0.5
    
    def _extract_basic_keywords(self, text: str) -> List[str]:
        """Extract basic keywords from text."""
        # Simple keyword extraction
        words = re.findall(r'\b\w+\b', text.lower())
        # Filter common words (this would be more sophisticated in practice)
        common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
                       'Ù…Ù†', 'Ø¥Ù„Ù‰', 'ÙÙŠ', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ù…Ø¹', 'Ù‡Ø°Ø§', 'Ù‡Ø°Ù‡', 'Ø°Ù„Ùƒ', 'Ø§Ù„ØªÙŠ', 'Ø§Ù„Ø°ÙŠ'}
        keywords = [word for word in set(words) if len(word) > 3 and word not in common_words]
        return keywords[:10]  # Return top 10 keywords
    
    def _calculate_readability(self, text: str) -> float:
        """Calculate basic readability score."""
        if not text:
            return 0
        
        words = len(text.split())
        sentences = len(re.split(r'[.!?]+', text))
        
        if sentences == 0:
            return 50
        
        avg_words_per_sentence = words / sentences
        
        # Simple readability score (higher is more readable)
        if avg_words_per_sentence <= 15:
            return 80
        elif avg_words_per_sentence <= 25:
            return 60
        else:
            return 40
    
    def _detect_spam_indicators(self, text: str) -> List[str]:
        """Detect potential spam indicators in text."""
        indicators = []
        
        # Check for excessive capitalization
        if sum(1 for c in text if c.isupper()) > len(text) * 0.5:
            indicators.append('Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ±Ø· Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„ÙƒØ¨ÙŠØ±Ø©')
        
        # Check for excessive punctuation
        if sum(1 for c in text if c in '!?') > len(text) * 0.1:
            indicators.append('Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ±Ø· Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¹Ø¬Ø¨ ÙˆØ§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…')
        
        # Check for suspicious patterns
        if re.search(r'(free|Ù…Ø¬Ø§Ù†ÙŠ|Ù…Ø¬Ø§Ù†Ø§).*(download|ØªØ­Ù…ÙŠÙ„)', text.lower()):
            indicators.append('Ù…Ø­ØªÙˆÙ‰ ØªØ±ÙˆÙŠØ¬ÙŠ Ù…Ø­ØªÙ…Ù„')
        
        return indicators
    
    def _generate_fallback_recommendations(self, user_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate fallback recommendations when AI fails."""
        return [
            {
                'title': 'ØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„',
                'description': 'Ø¬Ø±Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„',
                'action': 'explore_advanced_features',
                'priority': 'medium',
                'category': 'feature'
            },
            {
                'title': 'ØªØ®ØµÙŠØµ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª',
                'description': 'Ù‚Ù… Ø¨ØªØ®ØµÙŠØµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ',
                'action': 'customize_settings',
                'priority': 'low',
                'category': 'settings'
            },
            {
                'title': 'Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©',
                'description': 'ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ© Ù„Ù„Ø¨ÙˆØª',
                'action': 'check_new_features',
                'priority': 'low',
                'category': 'tip'
            }
        ]

